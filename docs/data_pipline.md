# ğŸ“Š Veri Pipeline KullanÄ±m KÄ±lavuzu

Bu dokÃ¼mantasyon, `src/data.py` modÃ¼lÃ¼nÃ¼n nasÄ±l kullanÄ±lacaÄŸÄ±nÄ± aÃ§Ä±klar.

---

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### 1. Veriyi Ä°ndir ve HazÄ±rla

```bash
# KÃ¼Ã§Ã¼k Ã¶rnek oluÅŸtur (Ã¶ÄŸrenme iÃ§in)
python scripts/prepare_data.py

# Veya Python iÃ§inden:
python
>>> from scripts.prepare_data import download_criteo_dataset
>>> download_criteo_dataset(sample_size=10_000)
```

### 2. Veriyi YÃ¼kle

```python
from src.data import load_criteo_sample

# Veriyi yÃ¼kle
df = load_criteo_sample("data/criteo_sample.parquet")
print(df.head())
```

### 3. Train/Test Split

```python
from src.data import train_test_split_uplift

# Split yap
X_train, X_test, y_train, y_test, t_train, t_test = \
    train_test_split_uplift(df, test_size=0.25, random_state=42)

print(f"Train size: {len(X_train)}")
print(f"Test size: {len(X_test)}")
```

### 4. Baseline Metrikleri Hesapla

```python
from src.data import calculate_baseline_metrics

metrics = calculate_baseline_metrics(y_train, t_train)
print(f"ATE: {metrics['ate']:.4f}")
print(f"Relative uplift: {metrics['relative_uplift']:.2%}")
```

---

## ğŸ“š Fonksiyon ReferansÄ±

### `load_criteo_sample(path)`

Criteo uplift veri setini yÃ¼kler.

**Parametreler:**
- `path` (str): Veri dosyasÄ±nÄ±n yolu (parquet veya csv)

**DÃ¶ndÃ¼rÃ¼r:**
- `pd.DataFrame`: YÃ¼klenen veri

**Ã–rnek:**
```python
df = load_criteo_sample("data/criteo_sample.parquet")
```

**Veri Seti YapÄ±sÄ±:**
```
Columns:
- f0, f1, ..., f11: Ã–zellikler (anonimleÅŸtirilmiÅŸ)
- treatment: 1 = reklam gÃ¶sterildi, 0 = gÃ¶sterilmedi
- visit: 1 = siteyi ziyaret etti, 0 = etmedi
- conversion: 1 = satÄ±n aldÄ±, 0 = almadÄ± (varsa)
- exposure: 1 = reklamÄ± gÃ¶rdÃ¼, 0 = gÃ¶rmedi (varsa)
```

---

### `get_features_target_treatment(df, features, target, treatment)`

DataFrame'den X, y, treatment'Ä± ayÄ±rÄ±r.

**Parametreler:**
- `df` (pd.DataFrame): Ham veri
- `features` (list, optional): KullanÄ±lacak Ã¶zellikler. None ise f0-f11 kullanÄ±lÄ±r
- `target` (str): Hedef deÄŸiÅŸken sÃ¼tun adÄ± (varsayÄ±lan: 'visit')
- `treatment` (str): Treatment sÃ¼tun adÄ± (varsayÄ±lan: 'treatment')

**DÃ¶ndÃ¼rÃ¼r:**
- `X` (pd.DataFrame): Ã–zellikler
- `y` (pd.Series): Hedef deÄŸiÅŸken
- `treatment` (pd.Series): Treatment gÃ¶stergesi

**Ã–rnek:**
```python
# VarsayÄ±lan kullanÄ±m
X, y, t = get_features_target_treatment(df)

# Ã–zel feature seÃ§imi
X, y, t = get_features_target_treatment(
    df, 
    features=['f0', 'f1', 'f2'],
    target='conversion'
)
```

---

### `train_test_split_uplift(df, test_size, random_state, stratify_treatment, ...)`

Uplift modeling iÃ§in train/test split yapar.

**âš ï¸ Ã–NEMLÄ°:** Treatment dengesi korunmalÄ±!

**Parametreler:**
- `df` (pd.DataFrame): TÃ¼m veri
- `test_size` (float): Test set oranÄ± (0-1 arasÄ±, varsayÄ±lan: 0.25)
- `random_state` (int): Random seed (varsayÄ±lan: 42)
- `stratify_treatment` (bool): Treatment oranÄ±nÄ± koru (varsayÄ±lan: True)
- `features` (list, optional): KullanÄ±lacak Ã¶zellikler
- `target` (str): Hedef deÄŸiÅŸken sÃ¼tun adÄ±
- `treatment` (str): Treatment sÃ¼tun adÄ±

**DÃ¶ndÃ¼rÃ¼r:**
- `X_train, X_test` (pd.DataFrame): Train ve test Ã¶zellikleri
- `y_train, y_test` (pd.Series): Train ve test hedef deÄŸiÅŸkenleri
- `t_train, t_test` (pd.Series): Train ve test treatment gÃ¶stergeleri

**Ã–rnek:**
```python
X_train, X_test, y_train, y_test, t_train, t_test = \
    train_test_split_uplift(
        df, 
        test_size=0.25, 
        random_state=42,
        stratify_treatment=True  # MUTLAKA True olmalÄ±!
    )

# Treatment dengesi kontrolÃ¼
print(f"Train treatment ratio: {t_train.mean():.2%}")
print(f"Test treatment ratio: {t_test.mean():.2%}")
```

**Neden Stratify?**
```python
# âŒ YANLIÅ: Stratify kullanmazsan
X_train, X_test, y_train, y_test, t_train, t_test = \
    train_test_split_uplift(df, stratify_treatment=False)
# Train: 45% treatment, Test: 55% treatment â†’ Dengesiz!

# âœ… DOÄRU: Stratify kullan
X_train, X_test, y_train, y_test, t_train, t_test = \
    train_test_split_uplift(df, stratify_treatment=True)
# Train: 50% treatment, Test: 50% treatment â†’ Dengeli!
```

---

### `check_treatment_balance(treatment, data_name)`

Treatment grubunun dengesini kontrol eder.

**Parametreler:**
- `treatment` (array-like): Treatment gÃ¶stergesi (0 veya 1)
- `data_name` (str): Veri setinin adÄ± (raporlama iÃ§in)

**DÃ¶ndÃ¼rÃ¼r:**
- `dict`: Treatment istatistikleri
  - `total`: Toplam Ã¶rnek sayÄ±sÄ±
  - `treatment`: Treatment grubu sayÄ±sÄ±
  - `control`: Control grubu sayÄ±sÄ±
  - `treatment_ratio`: Treatment oranÄ±
  - `control_ratio`: Control oranÄ±

**Ã–rnek:**
```python
stats = check_treatment_balance(t_train, "Training Set")

# Ã‡Ä±ktÄ±:
# ============================================================
# ğŸ¯ TREATMENT BALANCE: Training Set
# ============================================================
# Total samples:         7,500
# Treatment group:       3,750 (50.00%)
# Control group:         3,750 (50.00%)
# 
# âœ… Treatment groups are balanced
# ============================================================

print(f"Treatment ratio: {stats['treatment_ratio']:.2%}")
```

**Ä°deal Dengeler:**
- âœ… **30-70%**: Ä°yi denge
- âš ï¸ **20-80%**: Kabul edilebilir, dikkatli ol
- âŒ **<20% veya >80%**: KÃ¶tÃ¼ denge, model yanÄ±labilir

---

### `calculate_baseline_metrics(y, treatment)`

Baseline metriklerini hesaplar (ATE, conversion rates).

**Parametreler:**
- `y` (array-like): Outcome (0 veya 1)
- `treatment` (array-like): Treatment gÃ¶stergesi (0 veya 1)

**DÃ¶ndÃ¼rÃ¼r:**
- `dict`: Baseline metrikleri
  - `conversion_rate_treatment`: Treatment grubu conversion rate
  - `conversion_rate_control`: Control grubu conversion rate
  - `ate`: Average Treatment Effect (mutlak)
  - `relative_uplift`: GÃ¶receli uplift (%)

**Ã–rnek:**
```python
metrics = calculate_baseline_metrics(y_train, t_train)

print(f"CR (Treatment): {metrics['conversion_rate_treatment']:.2%}")
print(f"CR (Control):   {metrics['conversion_rate_control']:.2%}")
print(f"ATE:            {metrics['ate']:.4f}")
print(f"Relative:       {metrics['relative_uplift']:+.2%}")

# Ã‡Ä±ktÄ±:
# CR (Treatment): 4.50%
# CR (Control):   3.80%
# ATE:            0.0070
# Relative:       +18.42%
```

**FormÃ¼ller:**
```
ATE = E[Y|T=1] - E[Y|T=0]
Relative Uplift = ATE / E[Y|T=0]
```

**Yorumlama:**
- **ATE > 0**: Treatment pozitif etki yapÄ±yor âœ…
- **ATE = 0**: Treatment etkisiz â–
- **ATE < 0**: Treatment negatif etki yapÄ±yor âš ï¸

---

### `create_toy_dataset(n_samples, n_features, treatment_effect_size, ...)`

Test ve Ã¶ÄŸrenme iÃ§in toy dataset oluÅŸturur.

**Parametreler:**
- `n_samples` (int): Ã–rnek sayÄ±sÄ± (varsayÄ±lan: 1000)
- `n_features` (int): Ã–zellik sayÄ±sÄ± (varsayÄ±lan: 5)
- `treatment_effect_size` (float): Ortalama tedavi etkisi (varsayÄ±lan: 0.1)
- `noise_level` (float): GÃ¼rÃ¼ltÃ¼ seviyesi (varsayÄ±lan: 0.3)
- `random_state` (int): Random seed (varsayÄ±lan: 42)

**DÃ¶ndÃ¼rÃ¼r:**
- `pd.DataFrame`: SimÃ¼le edilmiÅŸ veri

**Ã–rnek:**
```python
# Basit toy dataset
df = create_toy_dataset(n_samples=1000)

# GÃ¼Ã§lÃ¼ uplift ile
df = create_toy_dataset(
    n_samples=5000,
    n_features=10,
    treatment_effect_size=0.2,  # %20 uplift
    noise_level=0.1              # Az gÃ¼rÃ¼ltÃ¼
)

# Heterogeneous uplift (bazÄ± mÃ¼ÅŸteriler pozitif, bazÄ±larÄ± negatif)
# â†’ GerÃ§ek uplift modeling senaryosu
```

**Ne Zaman Kullan?**
- âœ… HÄ±zlÄ± test iÃ§in
- âœ… Algoritma Ã¶ÄŸrenirken
- âœ… Debugging yaparken
- âŒ Production iÃ§in (gerÃ§ek veri kullan!)

---

## ğŸ¯ Tipik Workflow

### Tam Pipeline Ã–rneÄŸi

```python
import pandas as pd
from src.data import (
    load_criteo_sample,
    train_test_split_uplift,
    check_treatment_balance,
    calculate_baseline_metrics
)

# 1. VERÄ° YÃœKLEME
print("ğŸ“¥ Veri yÃ¼kleniyor...")
df = load_criteo_sample("data/criteo_sample.parquet")
print(f"âœ… {len(df):,} satÄ±r yÃ¼klendi")

# 2. TRAIN/TEST SPLIT
print("\nğŸ“Š Train/test split yapÄ±lÄ±yor...")
X_train, X_test, y_train, y_test, t_train, t_test = \
    train_test_split_uplift(
        df, 
        test_size=0.25, 
        random_state=42,
        stratify_treatment=True
    )

# 3. TREATMENT BALANCE KONTROLÃœ
print("\nâš–ï¸  Treatment dengesi kontrol ediliyor...")
check_treatment_balance(t_train, "Training Set")
check_treatment_balance(t_test, "Test Set")

# 4. BASELINE METRÄ°KLER
print("\nğŸ“ˆ Baseline metrikleri hesaplanÄ±yor...")
train_metrics = calculate_baseline_metrics(y_train, t_train)
test_metrics = calculate_baseline_metrics(y_test, t_test)

# 5. KAYDET
print("\nğŸ’¾ Kaydediliyor...")
import pickle

data = {
    'X_train': X_train,
    'X_test': X_test,
    'y_train': y_train,
    'y_test': y_test,
    't_train': t_train,
    't_test': t_test,
    'train_metrics': train_metrics,
    'test_metrics': test_metrics
}

with open('data/processed_data.pkl', 'wb') as f:
    pickle.dump(data, f)

print("âœ… Pipeline tamamlandÄ±!")
```

---

## ğŸ” Debugging Ä°puÃ§larÄ±

### Problem: Veri bulunamÄ±yor

```python
FileNotFoundError: data/criteo_sample.parquet not found
```

**Ã‡Ã¶zÃ¼m:**
```bash
# Ã–nce veriyi hazÄ±rla
python scripts/prepare_data.py
```

### Problem: Treatment dengesiz

```python
âš ï¸  WARNING: Treatment groups are imbalanced!
```

**Ã‡Ã¶zÃ¼m:**
```python
# Stratify kullan
X_train, X_test, y_train, y_test, t_train, t_test = \
    train_test_split_uplift(df, stratify_treatment=True)  # â† Bunu ekle
```

### Problem: ATE negatif

```python
ATE: -0.0234 (-14.5%)
âš ï¸  Treatment has NEGATIVE effect
```

**Yorumlama:**
- Bu NORMAL olabilir! BazÄ± kampanyalar negatif etki yapar.
- Ã–rn: Agresif indirimler, marka deÄŸerini dÃ¼ÅŸÃ¼rÃ¼p uzun vadede zararlÄ± olabilir
- Model iÅŸe yarar: Negatif uplift'li mÃ¼ÅŸterileri EXCLUDE edersin

### Problem: Bellek yetersiz

```python
MemoryError: Unable to allocate array
```

**Ã‡Ã¶zÃ¼m:**
```python
# KÃ¼Ã§Ã¼k sample kullan
df = load_criteo_sample("data/criteo_sample.parquet")

# Veya daha kÃ¼Ã§Ã¼k sample oluÅŸtur
from scripts.prepare_data import download_criteo_dataset
download_criteo_dataset(sample_size=10_000)  # 10K satÄ±r
```

---

## ğŸ“Š Veri Kalitesi Kontrolleri

### 1. Eksik DeÄŸer KontrolÃ¼

```python
print(df.isnull().sum())
# Hepsi 0 olmalÄ±!
```

### 2. Treatment Dengesi

```python
from src.data import check_treatment_balance
check_treatment_balance(df['treatment'], "Full Dataset")

# Ä°deal: 30-70% arasÄ±
# Kabul edilebilir: 20-80% arasÄ±
# KÃ¶tÃ¼: <20% veya >80%
```

### 3. Covariate Balance (RCT kontrolÃ¼)

```python
from scipy import stats

for col in ['f0', 'f1', 'f2']:  # Her feature iÃ§in
    x_t = df[df['treatment']==1][col]
    x_c = df[df['treatment']==0][col]
    
    t_stat, p_value = stats.ttest_ind(x_t, x_c)
    print(f"{col}: p-value = {p_value:.4f}")
    
    # p > 0.05 olmalÄ± (dengeli)
```

### 4. Outcome DaÄŸÄ±lÄ±mÄ±

```python
print("Conversion rates:")
print(f"Overall:    {df['visit'].mean():.2%}")
print(f"Treatment:  {df[df['treatment']==1]['visit'].mean():.2%}")
print(f"Control:    {df[df['treatment']==0]['visit'].mean():.2%}")

# Ã‡ok dÃ¼ÅŸÃ¼k (<1%) veya Ã§ok yÃ¼ksek (>50%) ise soru iÅŸareti
```

---

## ğŸ“ Ã–ÄŸrenme KaynaklarÄ±

### Teorik Arka Plan

1. **Randomized Controlled Trials (RCT)**
   - Treatment rastgele atanmalÄ±
   - Gruplar dengeli olmalÄ±
   - Yoksa causal inference yapamayÄ±z!

2. **Average Treatment Effect (ATE)**
   ```
   ATE = E[Y(1)] - E[Y(0)]
       = E[Y|T=1] - E[Y|T=0]  (RCT altÄ±nda)
   ```

3. **Conditional ATE (CATE)**
   ```
   Ï„(x) = E[Y(1) - Y(0) | X=x]
   ```
   â†’ Heterogeneous effects: Her mÃ¼ÅŸteri farklÄ± etki alÄ±r!

### Pratik Ä°puÃ§larÄ±

âœ… **YAP:**
- Treatment dengesini kontrol et
- Stratified split kullan
- Baseline metrikleri hesapla
- Train ve test setlerini ayrÄ± ayrÄ± analiz et

âŒ **YAPMA:**
- Treatment dengesiz olduÄŸunda devam etme
- Random split kullanma (stratify kullan!)
- Test setine bakmadan model seÃ§
- Toy dataset'le production kodu test etme

---

## ğŸ“š Ä°leri Konular

### Propensity Score Weighting

```python
# Treatment probability'yi tahmin et
from sklearn.linear_model import LogisticRegression

ps_model = LogisticRegression()
ps_model.fit(X_train, t_train)
propensity = ps_model.predict_proba(X_train)[:, 1]

# IPW (Inverse Propensity Weighting)
weights = np.where(t_train == 1, 1/propensity, 1/(1-propensity))
```

### Doubly Robust Estimation

```python
# Hem outcome modeli hem propensity score kullan
# â†’ Daha robust tahmin
# GÃ¼n 5+'te gÃ¶receÄŸiz
```

---

## ğŸ¤ KatkÄ±da Bulunma

Bug buldunuz mu? Ä°yileÅŸtirme Ã¶neriniz var mÄ±?

1. Issue aÃ§Ä±n: `github.com/sumeyraguclu/uplift-learn/issues`
2. Test ekleyin: `tests/test_data.py`
3. Pull request gÃ¶nderin!

---

## ğŸ“ Changelog

### v0.1.0 (GÃ¼n 1)
- âœ… `load_criteo_sample()` eklendi
- âœ… `train_test_split_uplift()` eklendi
- âœ… `check_treatment_balance()` eklendi
- âœ… `calculate_baseline_metrics()` eklendi
- âœ… `create_toy_dataset()` eklendi
- âœ… Unit testler yazÄ±ldÄ±
- âœ… DokÃ¼mantasyon tamamlandÄ±

---

**Son GÃ¼ncelleme**: GÃ¼n 1  
**Yazar**: SÃ¼meyra GÃ¼Ã§lÃ¼  
**Lisans**: MIT