"""
Criteo veri setini gÃ¼venli ÅŸekilde indir

100K dengeli sample iÃ§in optimize edildi
"""

import pandas as pd
import requests
from pathlib import Path
from tqdm import tqdm
import gzip
import shutil

def download_with_progress(url: str, output_path: Path):
    """Progress bar ile gÃ¼venli indirme"""
    print(f"\nğŸ“¥ Ä°ndiriliyor: {url}")
    print("â±ï¸  Tahmini sÃ¼re: 5-10 dakika")
    
    response = requests.get(url, stream=True)
    total_size = int(response.headers.get('content-length', 0))
    
    with open(output_path, 'wb') as f, tqdm(
        desc=output_path.name,
        total=total_size,
        unit='B',
        unit_scale=True,
        unit_divisor=1024,
    ) as pbar:
        for chunk in response.iter_content(chunk_size=8192):
            if chunk:
                f.write(chunk)
                pbar.update(len(chunk))
    
    print(f"âœ… Ä°ndirme tamamlandÄ±!")


def extract_gz(gz_path: Path, csv_path: Path):
    """GZ dosyasÄ±nÄ± aÃ§"""
    print(f"\nğŸ“¦ AÃ§Ä±lÄ±yor: {gz_path.name}")
    print("â±ï¸  Tahmini sÃ¼re: 2-3 dakika")
    
    with gzip.open(gz_path, 'rb') as f_in:
        with open(csv_path, 'wb') as f_out:
            shutil.copyfileobj(f_in, f_out)
    
    print(f"âœ… AÃ§Ä±ldÄ±: {csv_path.name}")


def create_balanced_sample(csv_path: Path, output_path: Path, sample_size: int = 100_000):
    """Dengeli sample oluÅŸtur"""
    print(f"\nğŸ”¬ {sample_size:,} satÄ±rlÄ±k dengeli sample oluÅŸturuluyor...")
    n_per_group = sample_size // 2
    
    # Treatment: Ä°lk 2M satÄ±rdan
    print(f"\n1ï¸âƒ£ Treatment sampling (ilk 2M satÄ±r)...")
    print("   â±ï¸  ~1 dakika...")
    
    df_head = pd.read_csv(csv_path, nrows=2_000_000)
    df_treatment = df_head[df_head['treatment'] == 1]
    
    if len(df_treatment) < n_per_group:
        raise ValueError(f"Yetersiz treatment! {len(df_treatment)} < {n_per_group}")
    
    df_treatment_sample = df_treatment.sample(n=n_per_group, random_state=42)
    print(f"   âœ… {n_per_group:,} treatment sample alÄ±ndÄ±")
    
    # Control: Son 3M satÄ±rdan
    print(f"\n2ï¸âƒ£ Control sampling (son 3M satÄ±r)...")
    print("   â±ï¸  ~2 dakika...")
    
    # Toplam satÄ±r sayÄ±sÄ± (yaklaÅŸÄ±k)
    total_lines = 13_900_000
    skip_rows = total_lines - 3_000_000
    
    df_tail = pd.read_csv(
        csv_path,
        skiprows=range(1, skip_rows),
        names=['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11',
               'treatment', 'conversion', 'visit', 'exposure'],
        low_memory=False
    )
    
    df_control = df_tail[df_tail['treatment'] == 0]
    
    if len(df_control) < n_per_group:
        print(f"   âš ï¸  Control az ({len(df_control):,}), tÃ¼mÃ¼nÃ¼ kullanÄ±yoruz")
        df_control_sample = df_control
    else:
        df_control_sample = df_control.sample(n=n_per_group, random_state=42)
        print(f"   âœ… {n_per_group:,} control sample alÄ±ndÄ±")
    
    # BirleÅŸtir
    print(f"\n3ï¸âƒ£ BirleÅŸtirme ve kaydetme...")
    df_balanced = pd.concat([df_treatment_sample, df_control_sample], ignore_index=True)
    df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)
    
    # Kaydet
    df_balanced.to_parquet(output_path, index=False, compression='snappy')
    
    # Rapor
    print(f"\nâœ… Kaydedildi: {output_path}")
    print(f"   Dosya boyutu: {output_path.stat().st_size / 1024**2:.1f} MB")
    print(f"   Toplam:    {len(df_balanced):,} satÄ±r")
    print(f"   Treatment: {(df_balanced['treatment']==1).sum():,} ({(df_balanced['treatment']==1).mean():.1%})")
    print(f"   Control:   {(df_balanced['treatment']==0).sum():,} ({(df_balanced['treatment']==0).mean():.1%})")
    
    # Baseline metrics
    print(f"\nğŸ“Š Baseline Metrikleri:")
    cr_t = df_balanced[df_balanced['treatment']==1]['visit'].mean()
    cr_c = df_balanced[df_balanced['treatment']==0]['visit'].mean()
    ate = cr_t - cr_c
    
    print(f"   CR (Treatment): {cr_t:.4f} ({cr_t:.2%})")
    print(f"   CR (Control):   {cr_c:.4f} ({cr_c:.2%})")
    print(f"   ATE:            {ate:+.4f}")
    
    if cr_c > 0:
        print(f"   Relative:       {ate/cr_c:+.2%}")


def main():
    print("=" * 60)
    print("ğŸš€ CRITEO DATASET Ä°NDÄ°RME VE HAZIRLIK")
    print("=" * 60)
    print("\nâ±ï¸  Toplam sÃ¼re: ~15-20 dakika")
    print("   â€¢ Ä°ndirme: 5-10 dk")
    print("   â€¢ AÃ§ma: 2-3 dk")
    print("   â€¢ Sampling: 3-5 dk")
    
    # Paths
    data_dir = Path("data")
    data_dir.mkdir(exist_ok=True)
    
    url = "http://go.criteo.net/criteo-research-uplift-v2.1.csv.gz"
    gz_file = data_dir / "criteo-uplift-v2.1.csv.gz"
    csv_file = data_dir / "criteo-uplift-v2.1.csv"
    parquet_file = data_dir / "criteo_sample.parquet"
    
    # 1. Ä°ndir
    if not gz_file.exists() and not csv_file.exists():
        try:
            download_with_progress(url, gz_file)
        except Exception as e:
            print(f"\nâŒ Ä°ndirme hatasÄ±: {e}")
            print("\nğŸ’¡ Alternatifler:")
            print("   1. Ä°nternet baÄŸlantÄ±nÄ±zÄ± kontrol edin")
            print("   2. VPN kullanmayÄ± deneyin")
            print("   3. Manuel indirin: " + url)
            return
    else:
        print("\nâœ… Dosya zaten mevcut, indirme atlanÄ±yor")
    
    # 2. AÃ§
    if gz_file.exists() and not csv_file.exists():
        try:
            extract_gz(gz_file, csv_file)
            # GZ'yi sil (yer kazan)
            gz_file.unlink()
            print("ğŸ—‘ï¸  GZ dosyasÄ± silindi")
        except Exception as e:
            print(f"\nâŒ AÃ§ma hatasÄ±: {e}")
            print("GZ dosyasÄ± bozuk olabilir. Silin ve tekrar indirin:")
            print(f"   del {gz_file}")
            return
    elif csv_file.exists():
        print("âœ… CSV zaten mevcut, aÃ§ma atlanÄ±yor")
    
    # 3. Sample oluÅŸtur
    if not parquet_file.exists():
        try:
            create_balanced_sample(csv_file, parquet_file, sample_size=100_000)
        except Exception as e:
            print(f"\nâŒ Sampling hatasÄ±: {e}")
            return
    else:
        print(f"\nâœ… {parquet_file.name} zaten mevcut!")
    
    # 4. Ã–zet
    print("\n" + "=" * 60)
    print("ğŸ‰ TAMAMLANDI!")
    print("=" * 60)
    
    print("\nğŸ“ OluÅŸturulan Dosyalar:")
    if csv_file.exists():
        print(f"   â€¢ {csv_file} ({csv_file.stat().st_size / 1024**3:.1f} GB)")
    if parquet_file.exists():
        print(f"   â€¢ {parquet_file} ({parquet_file.stat().st_size / 1024**2:.1f} MB)")
    
    print("\nğŸ’¾ Disk KullanÄ±mÄ±:")
    if csv_file.exists():
        print(f"   CSV: {csv_file.stat().st_size / 1024**3:.1f} GB")
        print("   ğŸ’¡ CSV'yi silebilirsiniz (parquet yeterli):")
        print(f"      del {csv_file}")
    
    print("\nğŸ¯ Sonraki AdÄ±mlar:")
    print("   1. âœ… Veri hazÄ±r!")
    print("   2. python tests/test_data.py -v  # Test et")
    print("   3. jupyter notebook  # Data exploration")
    print("   4. T-Learner implementasyonuna geÃ§!")


if __name__ == "__main__":
    main()